# Atividade 4 - Descoberta dos perfis de olhos

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="./.github/cover.png">
  <source media="(prefers-color-scheme: light)" srcset="./.github/cover_light.png">
  <img alt="Atividade 04 - Clusteriza√ß√£o" src="/.github/cover_light.png">
</picture>

## üìã Sobre a atividade

An√°lise de **aprendizado n√£o-supervisionado** para descobrir perfis/padr√µes de espessura epitelial em mapas oculares. O projeto compara tr√™s algoritmos de clustering (**K-Means**, **DBSCAN** e **K-Medoids**) para identificar grupos naturais de olhos com caracter√≠sticas similares de espessura do epit√©lio.

### üéØ Objetivo

Descobrir **quais s√£o os perfis de espessura epitelial** que existem na base de dados, agrupando olhos com caracter√≠sticas similares e comparando diferentes t√©cnicas de clusteriza√ß√£o.

### üìä Descri√ß√£o dos Dados

**Vari√°veis de Identifica√ß√£o:**
- `Index` = √≠ndice
- `pID` = ID do paciente
- `Age` = idade
- `Gender` = g√™nero/sexo
- `Eye` = olho (OS=esquerdo; OD=direito)

**Vari√°veis de Espessura Epitelial (Œºm):**
- `C` = central
- `S` = superior
- `ST` = superior temporal
- `T` = temporal
- `IT` = inferior temporal
- `I` = inferior
- `IN` = inferior nasal
- `N` = nasal
- `SN` = superior nasal

### üß≠ Distribui√ß√£o Espacial (Rosa dos Ventos)

A disposi√ß√£o espacial das regi√µes no olho pode ser visualizada como:

|        |       |        |
|--------|-------|--------|
| **ST** | **S** | **SN** |
| **T**  | **C** | **N**  |
| **IT** | **I** | **IN** |

> üí° Considere o enantiomorfismo dos olhos ao interpretar os resultados!

## üöÄ Como Executar

### 1Ô∏è‚É£ Instala√ß√£o das Depend√™ncias

```bash
pip install -r requirements.txt
```

### 2Ô∏è‚É£ Execu√ß√£o do Projeto

**Script Principal:**

```bash
python clustering.py
```

O script executa automaticamente:
- ‚úÖ **Pr√©-processamento** com valida√ß√£o de idade e tratamento de valores ausentes
- ‚úÖ **Remo√ß√£o de outliers** usando m√©todo IQR
- ‚úÖ **Otimiza√ß√£o autom√°tica** dos par√¢metros de cada algoritmo
- ‚úÖ **Clustering comparativo** com K-Means, DBSCAN e K-Medoids
- ‚úÖ **Gera√ß√£o de visualiza√ß√µes** comparativas
- ‚úÖ **Exporta√ß√£o de resultados** em CSV

**Execu√ß√£o com Outliers:**

O script executa duas an√°lises:
1. **COM remo√ß√£o de outliers** ‚Üí `results_with_outlier_removal/`
2. **SEM remo√ß√£o de outliers** ‚Üí `results_without_outlier_removal/`

**Importar M√≥dulos (Para Scripts Customizados):**

```python
from preprocessing import load_and_preprocess
from clustering import run_clustering, optimize_kmeans, optimize_dbscan

# Carregar e preprocessar dados
df, scaled_data, features, scaler = load_and_preprocess(
    'data/RTVue_20221110_MLClass.csv',
    remove_outliers=True
)

# Executar clustering
results, df, scaled_data, features = run_clustering(
    'data/RTVue_20221110_MLClass.csv',
    output_dir='results',
    remove_outliers=True
)
```

## üìÅ Estrutura do Projeto

```
07_UnsupervisedLearning2/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ RTVue_20221110_MLClass.csv         # Dataset de espessura epitelial
‚îÇ   ‚îî‚îÄ‚îÄ RTVue_20221110_MLClass.xlsx        # Vers√£o Excel
‚îú‚îÄ‚îÄ results_with_outlier_removal/          # Resultados COM remo√ß√£o de outliers
‚îÇ   ‚îú‚îÄ‚îÄ clustering_results.csv             # M√©tricas comparativas
‚îÇ   ‚îî‚îÄ‚îÄ clustering_comparison.png          # Visualiza√ß√£o comparativa
‚îú‚îÄ‚îÄ results_without_outlier_removal/       # Resultados SEM remo√ß√£o de outliers
‚îÇ   ‚îú‚îÄ‚îÄ clustering_results.csv             # M√©tricas comparativas
‚îÇ   ‚îî‚îÄ‚îÄ clustering_comparison.png          # Visualiza√ß√£o comparativa
‚îú‚îÄ‚îÄ preprocessing.py                       # M√≥dulo: Pr√©-processamento de dados
‚îú‚îÄ‚îÄ clustering.py                          # M√≥dulo: Algoritmos de clustering
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

### üéØ M√≥dulos Principais

- **`preprocessing.py`**: Carregamento, limpeza e normaliza√ß√£o dos dados
  - Valida√ß√£o de idade
  - Remo√ß√£o de valores ausentes
  - Detec√ß√£o e remo√ß√£o de outliers (IQR ou Z-Score)
  - Normaliza√ß√£o com StandardScaler

- **`clustering.py`**: Implementa√ß√£o dos algoritmos de clustering
  - K-Means com otimiza√ß√£o autom√°tica de k
  - DBSCAN com otimiza√ß√£o de eps e min_samples
  - K-Medoids para compara√ß√£o
  - Gera√ß√£o de visualiza√ß√µes comparativas

## üî¨ Metodologia

### 1. Pr√©-processamento (`preprocessing.py`)
- Carregamento dos dados do arquivo CSV
- Valida√ß√£o e limpeza de idade (0-120 anos)
- Sele√ß√£o das 9 vari√°veis de espessura epitelial
- Remo√ß√£o de valores ausentes
- **Detec√ß√£o e remo√ß√£o de outliers:**
  - **M√©todo IQR** (Interquartile Range): multiplier = 1.5
  - **M√©todo Z-Score**: threshold = 3
- Normaliza√ß√£o dos dados (StandardScaler)

### 2. Algoritmos de Clustering

#### **K-Means**
- Otimiza√ß√£o autom√°tica do n√∫mero de clusters (k=2 a k=10)
- M√©tricas: Silhouette Score e In√©rcia
- K fixo em 3 para consist√™ncia nas compara√ß√µes
- Par√¢metros: `n_init=10`, `random_state=42`

#### **DBSCAN**
- Otimiza√ß√£o autom√°tica de `eps` usando k-NN (k=5)
- Teste de m√∫ltiplos valores de `eps` e `min_samples`
- Detec√ß√£o autom√°tica de ru√≠do (outliers)
- Ideal para clusters de formas irregulares

#### **K-Medoids**
- Alternativa robusta ao K-Means
- Usa med√≥ides (amostras reais) em vez de centr√≥ides
- Mesma quantidade de clusters do K-Means (k=3)
- Mais resistente a outliers

### 3. Avalia√ß√£o e Compara√ß√£o
- **Silhouette Score**: Coes√£o vs separa√ß√£o dos clusters
- **Calinski-Harabasz Score**: Raz√£o de dispers√£o entre/dentro clusters
- **Davies-Bouldin Score**: Similaridade entre clusters
- Distribui√ß√£o de amostras por cluster
- Visualiza√ß√µes comparativas (boxplots e distribui√ß√µes)

### 4. Gera√ß√£o de Resultados
- Duas execu√ß√µes completas (com/sem outliers)
- CSV com m√©tricas comparativas
- Visualiza√ß√µes comparativas dos tr√™s algoritmos
- An√°lise da distribui√ß√£o das features por cluster

## üìä Resultados Esperados

O projeto gera duas an√°lises completas:

### üìÅ `results_with_outlier_removal/`
- **`clustering_results.csv`**: Tabela com m√©tricas dos tr√™s algoritmos
- **`clustering_comparison.png`**: Visualiza√ß√£o comparativa com:
  - Distribui√ß√£o de amostras por cluster
  - Boxplots das features normalizadas
  - Percentuais de cada cluster

### üìÅ `results_without_outlier_removal/`
- Mesma estrutura, mas sem remo√ß√£o de outliers
- √ötil para comparar o impacto da limpeza de dados

### üìà Informa√ß√µes Inclu√≠das

‚úÖ **Compara√ß√£o de Algoritmos**: K-Means vs DBSCAN vs K-Medoids  
‚úÖ **M√©tricas de Qualidade**: Silhouette, Calinski-Harabasz, Davies-Bouldin  
‚úÖ **Distribui√ß√£o de Clusters**: Quantidade e percentual de amostras  
‚úÖ **Detec√ß√£o de Ru√≠do**: Identifica√ß√£o de outliers pelo DBSCAN  
‚úÖ **Visualiza√ß√µes Comparativas**: Gr√°ficos profissionais para an√°lise

## üìà M√©tricas de Avalia√ß√£o

- **Silhouette Score** (-1 a 1): Mede qu√£o similar um ponto √© ao seu cluster vs outros clusters. **Maior √© melhor.**
- **Calinski-Harabasz Score**: Raz√£o da dispers√£o entre clusters e dentro dos clusters. **Maior √© melhor.**
- **Davies-Bouldin Score**: M√©dia da similaridade entre cada cluster e seu mais similar. **Menor √© melhor.**
- **In√©rcia** (K-Means): Soma das dist√¢ncias quadradas dos pontos aos centr√≥ides. **Menor √© melhor.**
- **N√∫mero de Ru√≠do** (DBSCAN): Quantidade de pontos identificados como outliers.

## üîß Personaliza√ß√£o

### Ajustar N√∫mero de Clusters

Edite em `clustering.py`:
```python
best_k = 3  # Altere o valor conforme necess√°rio
```

### Ajustar M√©todo de Remo√ß√£o de Outliers

Em `preprocessing.py`, na fun√ß√£o `load_and_preprocess`:
```python
# Op√ß√£o 1: IQR (padr√£o)
outlier_method="iqr"
iqr_multiplier=1.5  # Ajuste a sensibilidade

# Op√ß√£o 2: Z-Score
outlier_method="zscore"
zscore_threshold=3  # Ajuste o limiar
```

### Desabilitar Remo√ß√£o de Outliers

Em `clustering.py`:
```python
results = run_clustering(
    data_path,
    output_dir="results",
    remove_outliers=False  # Desabilita remo√ß√£o
)
```

## üìö Depend√™ncias

- pandas >= 2.1.3
- numpy >= 1.26.2
- scikit-learn >= 1.3.2
- scikit-learn-extra >= 0.3.0 (K-Medoids)
- scipy >= 1.11.4 (detec√ß√£o de outliers)
- matplotlib >= 3.8.2
- seaborn >= 0.13.0

## üéì Conceitos Aplicados

- **Aprendizado N√£o-Supervisionado**: Descoberta de padr√µes sem labels
- **Normaliza√ß√£o**: StandardScaler para equalizar escalas
- **Detec√ß√£o de Outliers**: IQR e Z-Score
- **Otimiza√ß√£o de Hiperpar√¢metros**: Grid search para DBSCAN, Elbow Method para K-Means
- **Avalia√ß√£o de Clusters**: M√∫ltiplas m√©tricas de valida√ß√£o interna
- **An√°lise Comparativa**: Avalia√ß√£o de diferentes algoritmos no mesmo dataset
